{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxpTkfSYb5ke+Ec/zYmP/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vramonlinebsc/neural_operator_surrogates/blob/main/surrogate_neural_operators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWGJqKCWE3Gm",
        "outputId": "07a758a9-0712-4086-84ad-8bbf9fb82860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Device: cuda\n",
            "\n",
            "======================================================================\n",
            "NMR SPIN DYNAMICS - PUBLICATION BENCHMARK\n",
            "======================================================================\n",
            "Config: N=[4, 6, 8, 10, 12], T=300, Epochs=200\n",
            "Samples: 200 train, 50 val\n",
            "Network: 6 layers, width 128, 24 modes\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "BENCHMARKING N=4, topology=chain\n",
            "======================================================================\n",
            "Generating 200 trajectories (N=4, chain)...\n",
            "  10/200 complete\n",
            "  20/200 complete\n",
            "  30/200 complete\n",
            "  40/200 complete\n",
            "  50/200 complete\n",
            "  60/200 complete\n",
            "  70/200 complete\n",
            "  80/200 complete\n",
            "  90/200 complete\n",
            "  100/200 complete\n",
            "  110/200 complete\n",
            "  120/200 complete\n",
            "  130/200 complete\n",
            "  140/200 complete\n",
            "  150/200 complete\n",
            "  160/200 complete\n",
            "  170/200 complete\n",
            "  180/200 complete\n",
            "  190/200 complete\n",
            "  200/200 complete\n",
            "  ✓ Saved dataset: dataset_N4_chain_train.pkl\n",
            "Generating 50 trajectories (N=4, chain)...\n",
            "  10/50 complete\n",
            "  20/50 complete\n",
            "  30/50 complete\n",
            "  40/50 complete\n",
            "  50/50 complete\n",
            "  ✓ Saved dataset: dataset_N4_chain_val.pkl\n",
            "\n",
            "Training surrogate...\n",
            "  ✓ Checkpoint: epoch 9\n",
            "Epoch 10/200 - Train: 0.832000, Val: 1.182016, Physics: 0.000387\n",
            "  ✓ Checkpoint: epoch 19\n",
            "Epoch 20/200 - Train: 0.808938, Val: 1.188884, Physics: 0.002367\n",
            "  ✓ Checkpoint: epoch 29\n",
            "Epoch 30/200 - Train: 0.816996, Val: 1.189616, Physics: 0.006250\n",
            "  ✓ Checkpoint: epoch 39\n",
            "Epoch 40/200 - Train: 0.804386, Val: 1.186531, Physics: 0.008324\n",
            "  ✓ Checkpoint: epoch 49\n",
            "Epoch 50/200 - Train: 0.809165, Val: 1.184662, Physics: 0.014832\n",
            "  ✓ Checkpoint: epoch 59\n",
            "Epoch 60/200 - Train: 0.806100, Val: 1.184830, Physics: 0.012653\n",
            "  ✓ Checkpoint: epoch 69\n",
            "Epoch 70/200 - Train: 0.795665, Val: 1.194900, Physics: 0.015793\n",
            "  ✓ Checkpoint: epoch 79\n",
            "Epoch 80/200 - Train: 0.784206, Val: 1.189383, Physics: 0.016798\n",
            "  ✓ Checkpoint: epoch 89\n",
            "Epoch 90/200 - Train: 0.784594, Val: 1.189360, Physics: 0.016395\n",
            "  ✓ Checkpoint: epoch 99\n",
            "Epoch 100/200 - Train: 0.788459, Val: 1.188858, Physics: 0.017672\n",
            "  ✓ Checkpoint: epoch 109\n",
            "Epoch 110/200 - Train: 0.787826, Val: 1.186507, Physics: 0.017345\n",
            "  ✓ Checkpoint: epoch 119\n",
            "Epoch 120/200 - Train: 0.788416, Val: 1.190694, Physics: 0.016700\n",
            "  ✓ Checkpoint: epoch 129\n",
            "Epoch 130/200 - Train: 0.785488, Val: 1.190437, Physics: 0.017772\n",
            "  ✓ Checkpoint: epoch 139\n",
            "Epoch 140/200 - Train: 0.781667, Val: 1.190601, Physics: 0.017370\n",
            "  ✓ Checkpoint: epoch 149\n",
            "Epoch 150/200 - Train: 0.783947, Val: 1.190723, Physics: 0.017892\n",
            "  ✓ Checkpoint: epoch 159\n",
            "Epoch 160/200 - Train: 0.789407, Val: 1.190864, Physics: 0.017813\n",
            "  ✓ Checkpoint: epoch 169\n",
            "Epoch 170/200 - Train: 0.780528, Val: 1.190924, Physics: 0.018262\n",
            "  ✓ Checkpoint: epoch 179\n",
            "Epoch 180/200 - Train: 0.783111, Val: 1.191008, Physics: 0.017833\n",
            "  ✓ Checkpoint: epoch 189\n",
            "Epoch 190/200 - Train: 0.788368, Val: 1.190989, Physics: 0.019175\n",
            "  ✓ Checkpoint: epoch 199\n",
            "Epoch 200/200 - Train: 0.786135, Val: 1.190980, Physics: 0.017819\n",
            "  ✓ Checkpoint: epoch 199\n",
            "\n",
            "Benchmarking methods...\n",
            "  [1/3] Exact method (dense matrix)...\n",
            "        Time: 0.0092s\n",
            "  [2/3] Krylov method (sparse)...\n",
            "        Time: 1.2471s, Error: 1.04e+00\n",
            "  [3/3] Neural surrogate...\n",
            "        Time: 0.003674s, Error: 1.384759\n",
            "\n",
            "Method          Time(s)      Error        Speedup\n",
            "-------------------------------------------------------\n",
            "Exact                0.0092  -            1.0×\n",
            "Krylov               1.2471     1.04e+00  0.0×\n",
            "Surrogate          0.003674     1.384759  2.5×\n",
            "\n",
            "======================================================================\n",
            "BENCHMARKING N=6, topology=chain\n",
            "======================================================================\n",
            "Generating 200 trajectories (N=6, chain)...\n",
            "  10/200 complete\n",
            "  20/200 complete\n",
            "  30/200 complete\n",
            "  40/200 complete\n",
            "  50/200 complete\n",
            "  60/200 complete\n",
            "  70/200 complete\n",
            "  80/200 complete\n",
            "  90/200 complete\n",
            "  100/200 complete\n",
            "  110/200 complete\n",
            "  120/200 complete\n",
            "  130/200 complete\n",
            "  140/200 complete\n",
            "  150/200 complete\n",
            "  160/200 complete\n",
            "  170/200 complete\n",
            "  180/200 complete\n",
            "  190/200 complete\n",
            "  200/200 complete\n",
            "  ✓ Saved dataset: dataset_N6_chain_train.pkl\n",
            "Generating 50 trajectories (N=6, chain)...\n",
            "  10/50 complete\n",
            "  20/50 complete\n",
            "  30/50 complete\n",
            "  40/50 complete\n",
            "  50/50 complete\n",
            "  ✓ Saved dataset: dataset_N6_chain_val.pkl\n",
            "\n",
            "Training surrogate...\n",
            "  ✓ Checkpoint: epoch 9\n",
            "Epoch 10/200 - Train: 1.307001, Val: 1.321539, Physics: 0.000000\n",
            "  ✓ Checkpoint: epoch 19\n",
            "Epoch 20/200 - Train: 1.268871, Val: 1.375302, Physics: 0.002347\n",
            "  ✓ Checkpoint: epoch 29\n",
            "Epoch 30/200 - Train: 1.265771, Val: 1.354639, Physics: 0.010113\n",
            "  ✓ Checkpoint: epoch 39\n",
            "Epoch 40/200 - Train: 1.239786, Val: 1.380572, Physics: 0.018784\n",
            "  ✓ Checkpoint: epoch 49\n",
            "Epoch 50/200 - Train: 1.231493, Val: 1.381941, Physics: 0.015430\n",
            "  ✓ Checkpoint: epoch 59\n",
            "Epoch 60/200 - Train: 1.224835, Val: 1.362809, Physics: 0.016596\n",
            "  ✓ Checkpoint: epoch 69\n",
            "Epoch 70/200 - Train: 1.229312, Val: 1.364748, Physics: 0.023698\n",
            "  ✓ Checkpoint: epoch 79\n",
            "Epoch 80/200 - Train: 1.231529, Val: 1.366832, Physics: 0.020986\n",
            "  ✓ Checkpoint: epoch 89\n",
            "Epoch 90/200 - Train: 1.227446, Val: 1.368410, Physics: 0.020584\n",
            "  ✓ Checkpoint: epoch 99\n",
            "Epoch 100/200 - Train: 1.235755, Val: 1.368707, Physics: 0.020486\n",
            "  ✓ Checkpoint: epoch 109\n",
            "Epoch 110/200 - Train: 1.230117, Val: 1.368723, Physics: 0.020478\n",
            "  ✓ Checkpoint: epoch 119\n",
            "Epoch 120/200 - Train: 1.228766, Val: 1.368685, Physics: 0.020484\n",
            "  ✓ Checkpoint: epoch 129\n",
            "Epoch 130/200 - Train: 1.231206, Val: 1.368668, Physics: 0.022786\n",
            "  ✓ Checkpoint: epoch 139\n",
            "Epoch 140/200 - Train: 1.238496, Val: 1.368670, Physics: 0.020487\n",
            "  ✓ Checkpoint: epoch 149\n",
            "Epoch 150/200 - Train: 1.224429, Val: 1.368669, Physics: 0.020487\n",
            "  ✓ Checkpoint: epoch 159\n",
            "Epoch 160/200 - Train: 1.226943, Val: 1.368670, Physics: 0.024046\n",
            "  ✓ Checkpoint: epoch 169\n",
            "Epoch 170/200 - Train: 1.233218, Val: 1.368670, Physics: 0.022786\n",
            "  ✓ Checkpoint: epoch 179\n",
            "Epoch 180/200 - Train: 1.233952, Val: 1.368669, Physics: 0.021256\n",
            "  ✓ Checkpoint: epoch 189\n",
            "Epoch 190/200 - Train: 1.229732, Val: 1.368669, Physics: 0.020487\n",
            "  ✓ Checkpoint: epoch 199\n",
            "Epoch 200/200 - Train: 1.226946, Val: 1.368669, Physics: 0.020487\n",
            "  ✓ Checkpoint: epoch 199\n",
            "\n",
            "Benchmarking methods...\n",
            "  [1/3] Exact method (dense matrix)...\n",
            "        Time: 0.0272s\n",
            "  [2/3] Krylov method (sparse)...\n",
            "        Time: 1.9122s, Error: 1.12e+00\n",
            "  [3/3] Neural surrogate...\n",
            "        Time: 0.002783s, Error: 1.827886\n",
            "\n",
            "Method          Time(s)      Error        Speedup\n",
            "-------------------------------------------------------\n",
            "Exact                0.0272  -            1.0×\n",
            "Krylov               1.9122     1.12e+00  0.0×\n",
            "Surrogate          0.002783     1.827886  9.8×\n",
            "\n",
            "======================================================================\n",
            "BENCHMARKING N=8, topology=chain\n",
            "======================================================================\n",
            "Generating 200 trajectories (N=8, chain)...\n",
            "  10/200 complete\n",
            "  20/200 complete\n",
            "  30/200 complete\n",
            "  40/200 complete\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg import expm_multiply\n",
        "from scipy.linalg import expm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "from typing import Tuple, List, Dict, Optional\n",
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass, asdict\n",
        "import hashlib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION & CHECKPOINTING\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Publication-quality experiment configuration\"\"\"\n",
        "    N_values: List[int]\n",
        "    topologies: List[str]\n",
        "    n_train_samples: int\n",
        "    n_val_samples: int\n",
        "    T: int\n",
        "    dt: float\n",
        "    epochs: int\n",
        "    batch_size: int\n",
        "    lr: float\n",
        "    modes: int\n",
        "    width: int\n",
        "    n_layers: int\n",
        "\n",
        "    def get_hash(self) -> str:\n",
        "        config_str = json.dumps(asdict(self), sort_keys=True)\n",
        "        return hashlib.md5(config_str.encode()).hexdigest()[:8]\n",
        "\n",
        "\n",
        "class CheckpointManager:\n",
        "    \"\"\"Manages all checkpoints with full resumability\"\"\"\n",
        "\n",
        "    def __init__(self, base_dir: str = \"checkpoints\"):\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.base_dir.mkdir(exist_ok=True)\n",
        "        self.results_dir = Path(\"results\")\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def save_dataset(self, dataset, N: int, topology: str, split: str):\n",
        "        path = self.base_dir / f\"dataset_N{N}_{topology}_{split}.pkl\"\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(dataset.data, f)\n",
        "        print(f\"  ✓ Saved dataset: {path.name}\")\n",
        "\n",
        "    def load_dataset(self, N: int, topology: str, split: str, T: int, dt: float):\n",
        "        path = self.base_dir / f\"dataset_N{N}_{topology}_{split}.pkl\"\n",
        "        if path.exists():\n",
        "            print(f\"  ✓ Loading dataset: {path.name}\")\n",
        "            dataset = NMRDataset(N, topology, 0, T, dt)\n",
        "            with open(path, 'rb') as f:\n",
        "                dataset.data = pickle.load(f)\n",
        "            return dataset\n",
        "        return None\n",
        "\n",
        "    def save_model(self, model: nn.Module, optimizer, scheduler, N: int,\n",
        "                   topology: str, epoch: int, history: Dict):\n",
        "        path = self.base_dir / f\"model_N{N}_{topology}_epoch{epoch}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'history': history,\n",
        "            'N': N,\n",
        "            'topology': topology\n",
        "        }, path)\n",
        "        print(f\"  ✓ Checkpoint: epoch {epoch}\")\n",
        "\n",
        "    def load_model(self, model: nn.Module, optimizer, scheduler, N: int, topology: str):\n",
        "        pattern = f\"model_N{N}_{topology}_epoch*.pt\"\n",
        "        checkpoints = list(self.base_dir.glob(pattern))\n",
        "\n",
        "        if not checkpoints:\n",
        "            return None, None\n",
        "\n",
        "        latest = max(checkpoints, key=lambda p: int(p.stem.split('epoch')[1]))\n",
        "        checkpoint = torch.load(latest, map_location='cpu')\n",
        "\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "        print(f\"  ✓ Resumed from epoch {checkpoint['epoch']}: {latest.name}\")\n",
        "        return checkpoint['epoch'], checkpoint.get('history', None)\n",
        "\n",
        "    def save_benchmark(self, result: Dict, N: int, topology: str):\n",
        "        path = self.base_dir / f\"benchmark_N{N}_{topology}.json\"\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(result, f, indent=2)\n",
        "\n",
        "    def load_benchmark(self, N: int, topology: str) -> Optional[Dict]:\n",
        "        path = self.base_dir / f\"benchmark_N{N}_{topology}.json\"\n",
        "        return json.load(open(path)) if path.exists() else None\n",
        "\n",
        "    def save_results_csv(self, results: Dict, name: str):\n",
        "        \"\"\"Save results as CSV for publication\"\"\"\n",
        "        df = pd.DataFrame(results)\n",
        "        path = self.results_dir / f\"{name}.csv\"\n",
        "        df.to_csv(path, index=False, float_format='%.6f')\n",
        "        print(f\"  ✓ Saved CSV: {path}\")\n",
        "        return path\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# OPTIMIZED SPIN SIMULATOR\n",
        "# ============================================================================\n",
        "\n",
        "class SpinSystemOptimized:\n",
        "    \"\"\"Exact quantum spin simulator with sparse/dense modes\"\"\"\n",
        "\n",
        "    def __init__(self, N: int, topology: str = 'chain', use_sparse: bool = None):\n",
        "        self.N = N\n",
        "        self.dim = 2 ** N\n",
        "        self.topology = topology\n",
        "        self.use_sparse = use_sparse if use_sparse is not None else (N > 10)\n",
        "        self._build_operators()\n",
        "\n",
        "    def _kron_list(self, ops: List, sparse: bool = False):\n",
        "        if sparse:\n",
        "            result = sp.csr_matrix(ops[0])\n",
        "            for op in ops[1:]:\n",
        "                result = sp.kron(result, op)\n",
        "            return result\n",
        "        result = ops[0]\n",
        "        for op in ops[1:]:\n",
        "            result = np.kron(result, op)\n",
        "        return result\n",
        "\n",
        "    def _build_operators(self):\n",
        "        sx = np.array([[0, 1], [1, 0]], dtype=complex)\n",
        "        sy = np.array([[0, -1j], [1j, 0]], dtype=complex)\n",
        "        sz = np.array([[1, 0], [0, -1]], dtype=complex)\n",
        "        identity = np.eye(2, dtype=complex)\n",
        "\n",
        "        if self.use_sparse:\n",
        "            sx, sy, sz = sp.csr_matrix(sx), sp.csr_matrix(sy), sp.csr_matrix(sz)\n",
        "            identity = sp.eye(2, dtype=complex, format='csr')\n",
        "\n",
        "        self.Ix, self.Iy, self.Iz = [], [], []\n",
        "\n",
        "        for i in range(self.N):\n",
        "            ops = [identity] * self.N\n",
        "            ops[i] = sx\n",
        "            self.Ix.append(self._kron_list(ops, self.use_sparse))\n",
        "            ops[i] = sy\n",
        "            self.Iy.append(self._kron_list(ops, self.use_sparse))\n",
        "            ops[i] = sz\n",
        "            self.Iz.append(self._kron_list(ops, self.use_sparse))\n",
        "\n",
        "    def get_coupling_pairs(self) -> List[Tuple[int, int]]:\n",
        "        if self.topology == 'chain':\n",
        "            return [(i, i+1) for i in range(self.N-1)]\n",
        "        elif self.topology == 'ring':\n",
        "            return [(i, (i+1) % self.N) for i in range(self.N)]\n",
        "        elif self.topology == 'star':\n",
        "            return [(0, i) for i in range(1, self.N)]\n",
        "        return []\n",
        "\n",
        "    def build_hamiltonian(self, Omega: np.ndarray, J: float):\n",
        "        if self.use_sparse:\n",
        "            H = sp.csr_matrix((self.dim, self.dim), dtype=complex)\n",
        "        else:\n",
        "            H = np.zeros((self.dim, self.dim), dtype=complex)\n",
        "\n",
        "        for i in range(self.N):\n",
        "            H = H + Omega[i] * self.Iz[i]\n",
        "\n",
        "        pairs = self.get_coupling_pairs()\n",
        "        for i, j in pairs:\n",
        "            if self.use_sparse:\n",
        "                H = H + 2*np.pi*J * (\n",
        "                    self.Ix[i].multiply(self.Ix[j]) +\n",
        "                    self.Iy[i].multiply(self.Iy[j]) +\n",
        "                    self.Iz[i].multiply(self.Iz[j])\n",
        "                )\n",
        "            else:\n",
        "                H = H + 2*np.pi*J * (\n",
        "                    self.Ix[i]@self.Ix[j] + self.Iy[i]@self.Iy[j] + self.Iz[i]@self.Iz[j]\n",
        "                )\n",
        "        return H\n",
        "\n",
        "    def simulate(self, Omega: np.ndarray, J: float, T: int, dt: float = 1e-4) -> Dict:\n",
        "        H = self.build_hamiltonian(Omega, J)\n",
        "        psi0 = np.ones(self.dim, dtype=complex) / np.sqrt(self.dim)\n",
        "        times = np.arange(T) * dt\n",
        "\n",
        "        Mx, My, I1z = np.zeros(T), np.zeros(T), np.zeros(T)\n",
        "\n",
        "        Ix_sum = sum(self.Ix)\n",
        "        Iy_sum = sum(self.Iy)\n",
        "        Iz_first = self.Iz[0]\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        if self.use_sparse:\n",
        "            for t_idx, t in enumerate(times):\n",
        "                psi_t = expm_multiply(-1j * H * t, psi0)\n",
        "                Mx[t_idx] = np.real(np.conj(psi_t) @ (Ix_sum @ psi_t))\n",
        "                My[t_idx] = np.real(np.conj(psi_t) @ (Iy_sum @ psi_t))\n",
        "                I1z[t_idx] = np.real(np.conj(psi_t) @ (Iz_first @ psi_t))\n",
        "        else:\n",
        "            U = expm(-1j * H * dt)\n",
        "            psi_t = psi0.copy()\n",
        "            for t_idx in range(T):\n",
        "                Mx[t_idx] = np.real(np.conj(psi_t) @ Ix_sum @ psi_t)\n",
        "                My[t_idx] = np.real(np.conj(psi_t) @ Iy_sum @ psi_t)\n",
        "                I1z[t_idx] = np.real(np.conj(psi_t) @ Iz_first @ psi_t)\n",
        "                psi_t = U @ psi_t\n",
        "\n",
        "        return {\n",
        "            'Mx': Mx, 'My': My, 'I1z': I1z,\n",
        "            'times': times, 'elapsed_time': time.time() - start\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET\n",
        "# ============================================================================\n",
        "\n",
        "class NMRDataset(Dataset):\n",
        "    def __init__(self, N: int, topology: str, n_samples: int, T: int, dt: float):\n",
        "        self.N, self.topology, self.n_samples = N, topology, n_samples\n",
        "        self.T, self.dt, self.data = T, dt, []\n",
        "\n",
        "    def generate_data(self):\n",
        "        if self.n_samples == 0:\n",
        "            return\n",
        "        print(f\"Generating {self.n_samples} trajectories (N={self.N}, {self.topology})...\")\n",
        "\n",
        "        system = SpinSystemOptimized(self.N, self.topology)\n",
        "        for i in range(self.n_samples):\n",
        "            Omega = np.random.uniform(-100, 100, self.N) * 2 * np.pi\n",
        "            J = np.random.uniform(5, 20)\n",
        "            result = system.simulate(Omega, J, self.T, self.dt)\n",
        "\n",
        "            params = np.concatenate([Omega, [J]])\n",
        "            observables = np.stack([result['Mx'], result['My'], result['I1z']], axis=1)\n",
        "            self.data.append({'params': params, 'observables': observables})\n",
        "\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"  {i+1}/{self.n_samples} complete\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return (torch.tensor(item['params'], dtype=torch.float32),\n",
        "                torch.tensor(item['observables'], dtype=torch.float32))\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# NEURAL OPERATOR\n",
        "# ============================================================================\n",
        "\n",
        "class SpectralConv1d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, modes: int):\n",
        "        super().__init__()\n",
        "        self.modes = modes\n",
        "        scale = 1 / (in_channels * out_channels)\n",
        "        self.weights = nn.Parameter(\n",
        "            scale * torch.rand(in_channels, out_channels, modes, 2, dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x_ft = torch.fft.rfft(x, dim=-1)\n",
        "        out_ft = torch.zeros(x.shape[0], self.weights.shape[1], x.size(-1)//2 + 1,\n",
        "                            dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes] = torch.einsum(\n",
        "            \"bix,iox->box\", x_ft[:, :, :self.modes],\n",
        "            torch.view_as_complex(self.weights)\n",
        "        )\n",
        "        return torch.fft.irfft(out_ft, n=x.size(-1), dim=-1)\n",
        "\n",
        "\n",
        "class PhysicsInformedFNO(nn.Module):\n",
        "    def __init__(self, modes: int = 16, width: int = 64, n_layers: int = 4,\n",
        "                 n_params: int = 13, n_outputs: int = 3):\n",
        "        super().__init__()\n",
        "        self.modes, self.width, self.n_layers = modes, width, n_layers\n",
        "\n",
        "        self.param_encoder = nn.Sequential(\n",
        "            nn.Linear(n_params, width), nn.GELU(), nn.Linear(width, width)\n",
        "        )\n",
        "        self.spectral_layers = nn.ModuleList([\n",
        "            SpectralConv1d(width, width, modes) for _ in range(n_layers)\n",
        "        ])\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv1d(width, width, 1) for _ in range(n_layers)\n",
        "        ])\n",
        "        self.output_projection = nn.Sequential(\n",
        "            nn.Linear(width, width), nn.GELU(), nn.Linear(width, n_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, params: torch.Tensor, time_steps: int) -> torch.Tensor:\n",
        "        x = self.param_encoder(params)\n",
        "        x = x.unsqueeze(-1).expand(-1, -1, time_steps)\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            x = self.spectral_layers[i](x) + self.conv_layers[i](x)\n",
        "            if i < self.n_layers - 1:\n",
        "                x = F.gelu(x)\n",
        "\n",
        "        return self.output_projection(x.transpose(1, 2))\n",
        "\n",
        "    def compute_physics_loss(self, pred: torch.Tensor) -> torch.Tensor:\n",
        "        Mx, My, I1z = pred[:, :, 0], pred[:, :, 1], pred[:, :, 2]\n",
        "        mag_loss = F.relu(torch.sqrt(Mx**2 + My**2) - 1.0).mean()\n",
        "        smooth_loss = ((Mx[:, 1:] - Mx[:, :-1])**2 + (My[:, 1:] - My[:, :-1])**2).mean()\n",
        "        diffusion_loss = F.relu(I1z[:, 1:] - I1z[:, :-1]).mean()\n",
        "        return mag_loss + 0.1 * smooth_loss + 0.1 * diffusion_loss\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "def train_surrogate(model: nn.Module, train_loader, val_loader, N: int,\n",
        "                   topology: str, epochs: int, lr: float, device: str,\n",
        "                   ckpt_mgr: CheckpointManager) -> Dict:\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "\n",
        "    start_epoch = 0\n",
        "    history = {'train_loss': [], 'val_loss': [], 'physics_loss': []}\n",
        "\n",
        "    loaded_epoch, loaded_history = ckpt_mgr.load_model(model, optimizer, scheduler, N, topology)\n",
        "    if loaded_epoch is not None:\n",
        "        start_epoch = loaded_epoch + 1\n",
        "        if loaded_history:\n",
        "            history = loaded_history\n",
        "\n",
        "    if start_epoch >= epochs:\n",
        "        print(\"  ✓ Training complete\")\n",
        "        return history\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        model.train()\n",
        "        train_losses, physics_losses = [], []\n",
        "\n",
        "        for params, observables in train_loader:\n",
        "            params, observables = params.to(device), observables.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(params, observables.shape[1])\n",
        "            data_loss = F.mse_loss(pred, observables)\n",
        "            physics_loss = model.compute_physics_loss(pred)\n",
        "            loss = data_loss + 0.01 * physics_loss\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(data_loss.item())\n",
        "            physics_losses.append(physics_loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for params, observables in val_loader:\n",
        "                params, observables = params.to(device), observables.to(device)\n",
        "                val_losses.append(F.mse_loss(model(params, observables.shape[1]), observables).item())\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        history['train_loss'].append(np.mean(train_losses))\n",
        "        history['val_loss'].append(np.mean(val_losses))\n",
        "        history['physics_loss'].append(np.mean(physics_losses))\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            ckpt_mgr.save_model(model, optimizer, scheduler, N, topology, epoch, history)\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Train: {history['train_loss'][-1]:.6f}, \"\n",
        "                  f\"Val: {history['val_loss'][-1]:.6f}, Physics: {history['physics_loss'][-1]:.6f}\")\n",
        "\n",
        "    ckpt_mgr.save_model(model, optimizer, scheduler, N, topology, epochs-1, history)\n",
        "    return history\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BENCHMARKING\n",
        "# ============================================================================\n",
        "\n",
        "def benchmark_all_methods(N_values: List[int], topology: str, config: ExperimentConfig,\n",
        "                         device: str) -> Dict:\n",
        "    ckpt_mgr = CheckpointManager()\n",
        "\n",
        "    results = {\n",
        "        'N': [], 'exact_time': [], 'krylov_time': [], 'surrogate_time': [],\n",
        "        'krylov_error': [], 'surrogate_error': []\n",
        "    }\n",
        "\n",
        "    for N in N_values:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"BENCHMARKING N={N}, topology={topology}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        existing = ckpt_mgr.load_benchmark(N, topology)\n",
        "        if existing:\n",
        "            print(\"  ✓ Using cached results\")\n",
        "            for k in results:\n",
        "                if k in existing:\n",
        "                    results[k].append(existing[k])\n",
        "            continue\n",
        "\n",
        "        # Load/generate datasets\n",
        "        train_ds = ckpt_mgr.load_dataset(N, topology, 'train', config.T, config.dt)\n",
        "        if not train_ds:\n",
        "            train_ds = NMRDataset(N, topology, config.n_train_samples, config.T, config.dt)\n",
        "            train_ds.generate_data()\n",
        "            ckpt_mgr.save_dataset(train_ds, N, topology, 'train')\n",
        "\n",
        "        val_ds = ckpt_mgr.load_dataset(N, topology, 'val', config.T, config.dt)\n",
        "        if not val_ds:\n",
        "            val_ds = NMRDataset(N, topology, config.n_val_samples, config.T, config.dt)\n",
        "            val_ds.generate_data()\n",
        "            ckpt_mgr.save_dataset(val_ds, N, topology, 'val')\n",
        "\n",
        "        train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n",
        "\n",
        "        # Train model\n",
        "        model = PhysicsInformedFNO(config.modes, config.width, config.n_layers, N+1, 3)\n",
        "        print(\"\\nTraining surrogate...\")\n",
        "        train_surrogate(model, train_loader, val_loader, N, topology,\n",
        "                       config.epochs, config.lr, device, ckpt_mgr)\n",
        "\n",
        "        # Benchmark\n",
        "        print(\"\\nBenchmarking methods...\")\n",
        "        Omega = np.random.uniform(-100, 100, N) * 2 * np.pi\n",
        "        J = 12.5\n",
        "\n",
        "        # Exact (dense)\n",
        "        print(\"  [1/3] Exact method (dense matrix)...\")\n",
        "        sys_exact = SpinSystemOptimized(N, topology, use_sparse=False)\n",
        "        exact_res = sys_exact.simulate(Omega, J, config.T, config.dt)\n",
        "        exact_time = exact_res['elapsed_time']\n",
        "        print(f\"        Time: {exact_time:.4f}s\")\n",
        "\n",
        "        # Krylov (sparse)\n",
        "        print(\"  [2/3] Krylov method (sparse)...\")\n",
        "        sys_krylov = SpinSystemOptimized(N, topology, use_sparse=True)\n",
        "        krylov_res = sys_krylov.simulate(Omega, J, config.T, config.dt)\n",
        "        krylov_time = krylov_res['elapsed_time']\n",
        "        krylov_err = np.sqrt(\n",
        "            np.mean((exact_res['Mx'] - krylov_res['Mx'])**2) +\n",
        "            np.mean((exact_res['My'] - krylov_res['My'])**2) +\n",
        "            np.mean((exact_res['I1z'] - krylov_res['I1z'])**2)\n",
        "        )\n",
        "        print(f\"        Time: {krylov_time:.4f}s, Error: {krylov_err:.2e}\")\n",
        "\n",
        "        # Surrogate\n",
        "        print(\"  [3/3] Neural surrogate...\")\n",
        "        model.eval()\n",
        "        model = model.to(device)\n",
        "        params_t = torch.tensor(np.concatenate([Omega, [J]]), dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "        # Warmup\n",
        "        with torch.no_grad():\n",
        "            _ = model(params_t, config.T)\n",
        "\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            pred = model(params_t, config.T)\n",
        "        surrogate_time = time.time() - start\n",
        "\n",
        "        pred = pred.squeeze().cpu().numpy()\n",
        "        surrogate_err = np.sqrt(\n",
        "            np.mean((exact_res['Mx'] - pred[:, 0])**2) +\n",
        "            np.mean((exact_res['My'] - pred[:, 1])**2) +\n",
        "            np.mean((exact_res['I1z'] - pred[:, 2])**2)\n",
        "        )\n",
        "        print(f\"        Time: {surrogate_time:.6f}s, Error: {surrogate_err:.6f}\")\n",
        "\n",
        "        result = {\n",
        "            'N': N, 'exact_time': exact_time, 'krylov_time': krylov_time,\n",
        "            'surrogate_time': surrogate_time, 'krylov_error': float(krylov_err),\n",
        "            'surrogate_error': float(surrogate_err),\n",
        "            'speedup_vs_exact': exact_time / surrogate_time,\n",
        "            'speedup_vs_krylov': krylov_time / surrogate_time\n",
        "        }\n",
        "\n",
        "        ckpt_mgr.save_benchmark(result, N, topology)\n",
        "        for k in results:\n",
        "            if k in result:\n",
        "                results[k].append(result[k])\n",
        "\n",
        "        print(f\"\\n{'Method':<15} {'Time(s)':<12} {'Error':<12} {'Speedup'}\")\n",
        "        print(\"-\" * 55)\n",
        "        print(f\"{'Exact':<15} {exact_time:>11.4f}  {'-':<12} {'1.0×'}\")\n",
        "        print(f\"{'Krylov':<15} {krylov_time:>11.4f}  {krylov_err:>11.2e}  {exact_time/krylov_time:.1f}×\")\n",
        "        print(f\"{'Surrogate':<15} {surrogate_time:>11.6f}  {surrogate_err:>11.6f}  {result['speedup_vs_exact']:.1f}×\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PLOTTING\n",
        "# ============================================================================\n",
        "\n",
        "def generate_publication_figures(results: Dict, ckpt_mgr: CheckpointManager):\n",
        "    \"\"\"Generate publication-quality figures\"\"\"\n",
        "    plt.style.use('seaborn-v0_8-paper')\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 12))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.35)\n",
        "\n",
        "    # Main scaling plot\n",
        "    ax1 = fig.add_subplot(gs[0, :])\n",
        "    ax1.semilogy(results['N'], results['exact_time'], 'o-',\n",
        "                label='Exact (Dense)', linewidth=3, markersize=12, color='#1f77b4')\n",
        "    ax1.semilogy(results['N'], results['krylov_time'], 's-',\n",
        "                label='Krylov (Sparse)', linewidth=3, markersize=12, color='#ff7f0e')\n",
        "    ax1.semilogy(results['N'], results['surrogate_time'], 'd-',\n",
        "                label='Neural Surrogate', linewidth=3, markersize=12, color='#2ca02c')\n",
        "    ax1.set_xlabel('Number of Spins (N)', fontsize=16, fontweight='bold')\n",
        "    ax1.set_ylabel('Wall-Clock Time (s)', fontsize=16, fontweight='bold')\n",
        "    ax1.set_title('Computational Scaling Comparison', fontsize=18, fontweight='bold', pad=20)\n",
        "    ax1.legend(fontsize=14, framealpha=0.95, loc='upper left')\n",
        "    ax1.grid(True, alpha=0.3, which='both')\n",
        "    ax1.tick_params(labelsize=14)\n",
        "\n",
        "    # Speedup comparison\n",
        "    ax2 = fig.add_subplot(gs[1, 0])\n",
        "    x = np.arange(len(results['N']))\n",
        "    width = 0.35\n",
        "    speedup_krylov = [results['exact_time'][i]/results['krylov_time'][i] for i in range(len(x))]\n",
        "    speedup_surr = [results['exact_time'][i]/results['surrogate_time'][i] for i in range(len(x))]\n",
        "\n",
        "    ax2.bar(x - width/2, speedup_krylov, width, label='Krylov', color='#ff7f0e', alpha=0.8, edgecolor='black')\n",
        "    ax2.bar(x + width/2, speedup_surr, width, label='Surrogate', color='#2ca02c', alpha=0.8, edgecolor='black')\n",
        "    ax2.set_xlabel('System Size (N)', fontsize=14, fontweight='bold')\n",
        "    ax2.set_ylabel('Speedup Factor', fontsize=14, fontweight='bold')\n",
        "    ax2.set_title('Speedup vs Exact Method', fontsize=15, fontweight='bold')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(results['N'])\n",
        "    ax2.legend(fontsize=12)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.tick_params(labelsize=12)\n",
        "\n",
        "    # Error analysis\n",
        "    ax3 = fig.add_subplot(gs[1, 1])\n",
        "    ax3.semilogy(results['N'], results['krylov_error'], 's-',\n",
        "                label='Krylov Error', linewidth=2.5, markersize=10, color='#ff7f0e')\n",
        "    ax3.semilogy(results['N'], results['surrogate_error'], 'd-',\n",
        "                label='Surrogate Error', linewidth=2.5, markersize=10, color='#2ca02c')\n",
        "    ax3.set_xlabel('System Size (N)', fontsize=14, fontweight='bold')\n",
        "    ax3.set_ylabel('RMSE vs Exact', fontsize=14, fontweight='bold')\n",
        "    ax3.set_title('Prediction Accuracy', fontsize=15, fontweight='bold')\n",
        "    ax3.legend(fontsize=12)\n",
        "    ax3.grid(True, alpha=0.3, which='both')\n",
        "    ax3.tick_params(labelsize=12)\n",
        "\n",
        "    # Efficiency plot\n",
        "    ax4 = fig.add_subplot(gs[1, 2])\n",
        "    efficiency_surr = [results['surrogate_error'][i] * results['surrogate_time'][i] for i in range(len(x))]\n",
        "    efficiency_krylov = [results['krylov_error'][i] * results['krylov_time'][i] for i in range(len(x))]\n",
        "\n",
        "    ax4.semilogy(results['N'], efficiency_krylov, 's-',\n",
        "                label='Krylov', linewidth=2.5, markersize=10, color='#ff7f0e')\n",
        "    ax4.semilogy(results['N'], efficiency_surr, 'd-',\n",
        "                label='Surrogate', linewidth=2.5, markersize=10, color='#2ca02c')\n",
        "    ax4.set_xlabel('System Size (N)', fontsize=14, fontweight='bold')\n",
        "    ax4.set_ylabel('Error × Time', fontsize=14, fontweight='bold')\n",
        "    ax4.set_title('Computational Efficiency', fontsize=15, fontweight='bold')\n",
        "    ax4.legend(fontsize=12)\n",
        "    ax4.grid(True, alpha=0.3, which='both')\n",
        "    ax4.tick_params(labelsize=12)\n",
        "\n",
        "    # Time breakdown table\n",
        "    ax5 = fig.add_subplot(gs[2, :])\n",
        "    ax5.axis('tight')\n",
        "    ax5.axis('off')\n",
        "\n",
        "    table_data = [['N', 'Exact (s)', 'Krylov (s)', 'Surrogate (s)', 'KrylovErr', 'Surr Err', 'Speedup']]\n",
        "    for i in range(len(results['N'])):\n",
        "        table_data.append([\n",
        "            f\"{results['N'][i]}\",\n",
        "            f\"{results['exact_time'][i]:.4f}\",\n",
        "            f\"{results['krylov_time'][i]:.4f}\",\n",
        "            f\"{results['surrogate_time'][i]:.6f}\",\n",
        "            f\"{results['krylov_error'][i]:.2e}\",\n",
        "            f\"{results['surrogate_error'][i]:.6f}\",\n",
        "            f\"{results['exact_time'][i]/results['surrogate_time'][i]:.1f}×\"\n",
        "        ])\n",
        "\n",
        "    table = ax5.table(cellText=table_data, cellLoc='center', loc='center',\n",
        "                     colWidths=[0.1, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15])\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(11)\n",
        "    table.scale(1, 2.5)\n",
        "\n",
        "    # Style header row\n",
        "    for i in range(7):\n",
        "        table[(0, i)].set_facecolor('#4CAF50')\n",
        "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "    plt.savefig(ckpt_mgr.results_dir / 'comprehensive_benchmark.png',\n",
        "                dpi=300, bbox_inches='tight', facecolor='white')\n",
        "    print(\"\\n✓ Saved: comprehensive_benchmark.png\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"\\nDevice: {device}\")\n",
        "\n",
        "    # Publication config\n",
        "    config = ExperimentConfig(\n",
        "        N_values=[4, 6, 8, 10, 12],  # Extended range\n",
        "        topologies=['chain'],\n",
        "        n_train_samples=200,  # More data\n",
        "        n_val_samples=50,\n",
        "        T=300,  # Longer trajectories\n",
        "        dt=1e-4,\n",
        "        epochs=200,  # More training\n",
        "        batch_size=16,\n",
        "        lr=1e-3,\n",
        "        modes=24,  # Larger network\n",
        "        width=128,\n",
        "        n_layers=6\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"NMR SPIN DYNAMICS - PUBLICATION BENCHMARK\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Config: N={config.N_values}, T={config.T}, Epochs={config.epochs}\")\n",
        "    print(f\"Samples: {config.n_train_samples} train, {config.n_val_samples} val\")\n",
        "    print(f\"Network: {config.n_layers} layers, width {config.width}, {config.modes} modes\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    ckpt_mgr = CheckpointManager()\n",
        "\n",
        "    # Run benchmark\n",
        "    results = benchmark_all_methods(config.N_values, 'chain', config, device)\n",
        "\n",
        "    # Save results\n",
        "    ckpt_mgr.save_results_csv(results, 'benchmark_results')\n",
        "\n",
        "    with open(ckpt_mgr.results_dir / 'benchmark_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    # Generate figures\n",
        "    generate_publication_figures(results, ckpt_mgr)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BENCHMARK COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Results: {ckpt_mgr.results_dir}\")\n",
        "    print(f\"Checkpoints: {ckpt_mgr.base_dir}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}